{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2be421-5e4a-4fe7-86a9-89a1ad8b850b",
   "metadata": {},
   "source": [
    "# Emergence of Latent Binary Encoding in Deep Neural Network Classifiers\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8c6c3-56b1-46d4-ad8e-36c600973117",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Supplementary material to reproduce results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92582aa6-9c17-4026-8e2e-178fde9a7d3a",
   "metadata": {},
   "source": [
    "The aim of this notebook is to show how to train a network implementing a binary encoding layer, in order to demonstrate the emergence of binary encoding. Results can be compared against other model architectures in an ablation study to highlight the benefits of the implementation of a binary encoding layer. This is a demonstrative notebook, and results obtained here do not reproduce results presented in the manuscript, which require substantially longer trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847d468-13eb-4ae1-8a5e-a5333b25cdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os \n",
    "import shutil\n",
    "import yaml\n",
    "import argparse\n",
    "import copy\n",
    "import importlib\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from binary_encoding.networks import ResNet\n",
    "from binary_encoding.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a04bf2-cd5c-4315-a15e-ced91872d4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1cf50-1704-4a3f-aecb-f95d8cd2455f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mean_std(dataset):\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    \n",
    "    data = next(iter(loader))[0].numpy()\n",
    "\n",
    "    mean = np.mean(data, axis=(0, 2, 3))\n",
    "    std = np.std(data, axis=(0, 2, 3))\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ea54c-2636-498d-bcb3-5cec003886c1",
   "metadata": {},
   "source": [
    "In this experiment we perform training with the CIFAR10 dataset. Data are normalized, and augmented during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be339cd-ced5-4e31-869d-713f460a75f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_dataset = 'CIFAR10'\n",
    "\n",
    "torch_module = importlib.import_module(\"torchvision.datasets\")\n",
    "torch_dataset = getattr(torch_module, name_dataset)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torch_dataset('../datasets', train=True, download=True, transform=transform)\n",
    "trainset_mean, trainset_std = compute_mean_std(trainset)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(trainset_mean, trainset_std),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(trainset[0][0][0][0].shape[0], padding=4),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(trainset_mean, trainset_std),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torch_dataset ('../datasets', train=True, download=True, transform=transform)\n",
    "testset = torch_dataset ('../datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "num_classes = len(set(trainset.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb1787-af82-44e2-98a6-af64e43e924a",
   "metadata": {},
   "source": [
    "We employ a ResNet18 architecture as backbone, implementig SiLU activation function in non-linear layers. In our ablation study the penultimte layer features 4 nodes, that is the minimum possible value of dimensions for a hypercube to have a number of vertices larger than 10 - that is the number of classes of the dataset we utilize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46463130-577e-4a1f-ae38-12c6c828418c",
   "metadata": {},
   "source": [
    "Optimization is done with a AdamW optimizer with weight decay set to $5\\times 10^{-4}$. The starting value of $\\gamma$, a positive scalar which multiplies the compressing factor in the loss function, is initially set to $0.01$. This value is scheduled to be multiplied at each epoch by a factor of $1.3$. We use a batch size of $128$ and learnign rate is equal to $5\\times 10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241fd859-a7de-40e2-a243-d089be06ae25",
   "metadata": {},
   "source": [
    "Each training is done for $50$ epochs and logging time is set to $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42abbc-5a92-4c11-b2a5-81cda3d1aa67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "logging = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468ced1-9d85-4337-ae07-b54edd81cd62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "architecture={\n",
    "    \n",
    "    \"backbone\": \"ResNet\",\n",
    "    \"backbone_model\": 18,\n",
    "    \"hypers\":{\n",
    "        \n",
    "        \"nodes_head\": [],\n",
    "        \"penultimate_nodes\": 4,\n",
    "        \"activation\": 'SiLU',\n",
    "        \n",
    "    }\n",
    "}    \n",
    "\n",
    "training={\n",
    "    \"hypers\":{\n",
    "        \n",
    "        \"batch_size\": 128,\n",
    "        \"epochs\": epochs,\n",
    "        \"gamma\": 0.01,\n",
    "        \"gamma_scheduler_factor\": 1.3,\n",
    "        \"gamma_scheduler_step\": 1,\n",
    "        \"logging_pen\": True,\n",
    "        \"logging\": logging,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"weight_decay\": 0.0005,\n",
    "        \"lr\":0.0005,      \n",
    "\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3545b-e332-418e-a7cf-ba405504ad0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dims = trainset[0][0].shape[0]*trainset[0][0].shape[1]*trainset[0][0].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f347d-66b0-4c0a-9d75-c7ba69d32d79",
   "metadata": {},
   "source": [
    "We perform a different training for each of the 4 different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762af59f-0d0e-4c4a-9890-c3c83dcc1eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = ['bin_enc', 'no_pen', 'lin_pen', 'nonlin_pen']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    classifier = ResNet (\n",
    "        model=model,\n",
    "        architecture=architecture,\n",
    "        num_classes=num_classes,\n",
    "        input_dims = input_dims\n",
    "        )\n",
    "    classifier = classifier.to(device)\n",
    "    trainer = Trainer(\n",
    "        device=device, \n",
    "        network=classifier, \n",
    "        trainset=trainset,\n",
    "        testset=testset,\n",
    "        training_hypers=training['hypers'], \n",
    "        model=model, \n",
    "        encoding_metrics=True,\n",
    "        store_penultimate=True,\n",
    "        verbose=True)\n",
    "\n",
    "    results[model] = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c440df7-9e33-47a0-87e9-459d8ed23261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_bin = '#1f77b4'\n",
    "color_lin = '#2ca02c'\n",
    "color_no = '#ff7f0e'\n",
    "color_nonlin = '#d62728'\n",
    "sns.set(style=\"whitegrid\")\n",
    "alpha=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00457ed9-459b-4eae-9aae-6371ce428445",
   "metadata": {},
   "source": [
    "Plots showing the accuracy of the networks for the training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdf907-258d-4d64-a273-43ca2a84bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(logging, epochs+logging,logging)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "\n",
    "y = results['bin_enc']['accuracy_train'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='BinEnc', ax=axes[0], color=color_bin)\n",
    "y = results['lin_pen']['accuracy_train'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='LinPen', color=color_lin, ax=axes[0])\n",
    "y = results['nonlin_pen']['accuracy_train'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='NonlinPen', ax=axes[0], color=color_nonlin)\n",
    "y = results['no_pen']['accuracy_train'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='NoPen', ax=axes[0], color=color_no)\n",
    "\n",
    "y = results['bin_enc']['accuracy_test'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='BinEnc', ax=axes[1], color=color_bin)\n",
    "y = results['lin_pen']['accuracy_test'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='LinPen', color=color_lin, ax=axes[1])\n",
    "y = results['nonlin_pen']['accuracy_test'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='NonlinPen', ax=axes[1], color=color_nonlin)\n",
    "y = results['no_pen']['accuracy_test'].reshape(-1)\n",
    "sns.lineplot(x=x, y=y, marker='o',label='NoPen', ax=axes[1], color=color_no)\n",
    "\n",
    "axes[0].set_title('Trainset')\n",
    "axes[1].set_title('Testset')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('Epochs')\n",
    "axes[1].set_xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcfbfe-1c20-42c4-b5cb-a1e1703783e9",
   "metadata": {},
   "source": [
    "Auroc values and perturbation score as defined in the manucscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c5d67-02f9-4acc-8294-2108bfbfa65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Auroc')\n",
    "for model in models:\n",
    "    print(model, ': ', np.around(results[model]['mahalanobis_score']['auroc'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229f3318-e0ba-4bcb-968a-b94b715da223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perturbation score')\n",
    "for model in models:\n",
    "    print(model, ': ', np.around(results[model]['perturbation_score'],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9bf66-3be9-42ad-91e9-6f5e454a8b65",
   "metadata": {},
   "source": [
    "Histograms built with the latent penultimate value of all elemements in the training set. In the BinEnc model, we can observe emergence of binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1934b5c-b5c3-4fc8-85a0-c579389fc7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 5))\n",
    "\n",
    "node_bin_enc = 0\n",
    "node_lin_pen = 0\n",
    "node_nonlin_pen = 0\n",
    "node_no_pen = 0\n",
    "\n",
    "axes[0][0].hist(results['bin_enc']['penultimate_train'][:,node_bin_enc], bins=100, density=True)\n",
    "axes[0][1].hist(results['lin_pen']['penultimate_train'][:,node_lin_pen], bins=100, density=True)\n",
    "axes[1][0].hist(results['nonlin_pen']['penultimate_train'][:,node_nonlin_pen], bins=100, density=True)\n",
    "axes[1][1].hist(results['no_pen']['penultimate_train'][:,node_no_pen], bins=100, density=True)\n",
    "\n",
    "axes[0,0].set_title(label='BinEnc',)\n",
    "axes[0,1].set_title(label='LinPen',)\n",
    "axes[1,0].set_title(label='NonlinPen')\n",
    "axes[1,1].set_title(label='NoPen',)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bin_enc]",
   "language": "python",
   "name": "conda-env-bin_enc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
